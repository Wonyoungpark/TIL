{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mldl_md.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP9B4JS5zLLxl4UeFX0bOjK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 머신러닝 & 딥러닝\n","\n","📖 \bBook\n","----\n","[혼자 공부하는 머신러닝 + 딥러닝](http://www.yes24.com/Product/Goods/96024871)\n","\n","실습 환경\n","----\n","- 구글 코랩 : [Colab](https://colab.research.google.com/)\n","- Python\n","\n","인공지능 (Artificial Intelligence)\n","----\n","사람처럼 학습하고 추론할 수 있는 지증을 가진 컴퓨터 시스템을 만드는 기술\n","- 인공일반지능(Artificial general intelligence), 강인공지능(Strong AI) : 사람과 구분하기 어려운 컴퓨터 시스템\n","- 약인공지능(Weak AI) : 음성비서, 자율주행차, 알파고\n","\n","머신러닝 (Machine Learning)\n","----\n","자동으로 데이터에서 규칙을 학습하는 알고리즘<br/>\n","지능을 구현하는 소프트웨어 담당<br/>\n","라이브러리 : scikit-learn(사이킷런)\n","\n","딥러닝 (Deep Learning)\n","----\n","머신러닝 알고리즘 중 인공 신경망을 기반으로한 방법<br/>\n","라이브러리 : TensorFlow(텐서플로), PyTorch(파이토치)\n"],"metadata":{"id":"wCoJzQPxUhw-"}},{"cell_type":"markdown","source":["# Machin Learning\n","**용어**\n","- 특성 : 데이터의 특징\n","- 모델 : 알고리즘이 구현된 객체\n","- 훈련 : 모델에 데이터를 전달해 규칙을 학습하는 과정\n","- 정확도 = (정확히 맞힌 개수) / (전체 데이터 개수)\n","- 테스트 세트 : 평가에 사용하는 데이터\n","- 훈련 세트 : 훈련에 사용하는 데이터\n","- 샘플링 편향 : 훈련 세트와 테스트 세트에 샘플링이 치우쳐짐. 전체 데이터를 대표하지 못하는 현상\n","- 데이터 전처리(data preprocessing) : 머신러닝 모델에 훈련 데이터를 주입하기 전에 가공하는 단계\n","- 표준점수 : 훈련 세트의 스케일을 변경하는 방법, 각 특성값이 평균에서 표준편차의 몇 배만큼 떨어져 있는지를 표현<br/>\n","  = (훈련 데이터-평균)/표준편차\n","- 브로드캐스팅 : 크기가 다른 넘파이 배열에서 자동으로 산칙연산을 모든 행/열로 확장해 수행\n","- 결정계수(R^2, coefficient of determination) : 회귀의 성능 측정 도구\n","- 과대적합 : 훈련 세트 성능 > 테스트 세트 성능\n","- 과소적합 : 훈련 세트 성능 < 테스트 세트 성능 \b| 둘 다 낮을 경우\n","- 파라미터\n","  - 모델 파라미터 : 머신러닝 알고리즘이 찾은 값 (coef_,intercept_)\n","  - 하이퍼파라미터 : 사전에 우리가 지정해야하는 값 (alpha)\n","- 모델 기반 학습 : 최적의 모델 파라미터를 찾는 훈련\n","- 훈련 기반 학습 : 훈련 세트를 저장하는 훈련 (k-최근접 이웃)\n","- 특성 공학(Feature Engineering) : 주어진 특성으로 새로운 특성을 생성\n","- 규제(Regularization) : 훈련 세트에 과대 적합되지 않도록 만듦\n","- 다중 분류 : target 데이터에 2개 이상의 클래스가 포함된 문제\n","- 시그모이드 함수(sigmoid function) : 선형 방정식의 출력을 0~1 사이 값으로 압축\n","  - 출력값>0.5 : 양성 클래스, 출력값<=0.5 : 음성 클래스\n","- 소프트맥스 함수(softmax function) : 여러 선형 방정식의 출력 결과를 정규화하여 합이 1이 되도록 함\n","- 점진적 학습, 온라인 학습 : 훈련한 모델을 버리지 않고 새로운 데이터에 대해서만 추가 훈련\n","- 에포크(epoch) : 확률적 경사 하강법에서 전체 샘플을 모두 사용하는 한번의 방법\n","- 손실 함수(loss function) : 확률적 경사 하강법이 최적화할 대상, 샘플 하나에 대한 손실을 정의\n","  - 이진 분류 : 로지스틱 회귀(이진 크로스엔트로피) 손실 함수\n","  - 다중 분류 : 크로스엔트로피 손실 함수\n","- 비용 함수(cost function) : 훈련 세트에 있는 모든 샘플에 대한 손실 함수의 합\n","\n","\n","---\n","\n","\n","**알고리즘**\n","- 지도 알고리즘(supervised learning) : 훈련데이터 [입력데이터 & 타깃데이터]\n","  - 분류 : 몇 개의 클래스 중 하나로 분류\n","  - 회귀(regression) : 임의의 수치 예측, 두 변수 사이의 상관관계를 분석\n","- 비지도 알고리즘(unspervised learning) : 입력데이터\n","- k-최근접 이웃 알고리즘 : 주위의 다른 데이터를 보고 다수를 차지하는 것을 정답으로 사용\n","- 선형 회귀(Linear Regression) : 특성과 타깃 사이의 관계를 표현하는 선형 방정식\n","  - 특성이 한개 : 직선 방정식\n","  - 릿지 회귀(Ridge) : 계수를 제곱한 값으로 규제 적용 => 과대적합 완화\n","  - 라쏘 회귀(Lasso) : 계수의 절댓값을 기준으로 규제 적용\n","- 다항 회귀(Polynomial Regression) : 다항식을 사용해 특성과 타깃 사이의 관계 표시, 선형 모델로 표현 가능\n","- 다중 회귀(Multiple Regression) : 여러개의 특성을 사용한 회귀 모델\n","- 로지스틱 회귀(logistic regression) : 선형 방정식을 사용한 분류 알고리즘\n","  - 이진 분류 : 시그모이드 함수(=로지스틱스 함수)\n","  - 다중 분류 : 소프트맥스 함수(=정규화된 지수 함수)\n","- 확률적 경사 하강법(Stochastic Gradient Descent) : 훈련 세트에서 랜덤하게 하나의 샘플을 고르는 것\n","- 미니배치 경사 하강법(minibatch gradient descent) : 무작위로 여러개의 샘플을 선택\n","- 배치 경사 하강법(batch gradient descent) : 한번에 전체 샘플을 선택해 사용\n","\n","\n","---\n","\n","\n","**패키지**\n","- matplotlib\n","  - scatter() : 산점도를 그림\n","\n","- scikit-learn\n","  - KNeighborsClassifier() : k-최근접 이웃 분류 모델 생성 클래스\n","  - fit(훈련할 특성, 정답 데이터) : 사이킷런 모델을 훈련\n","  - score(훈련할 특성, 정답 데이터) : 훈련된 모델의 성능 측정, 정확도 측정\n","  - predict(새 특성 데이터) : 훈련된 모델로 새로운 데이터의 정답 예측\n","  - train_test_split() : 훈련 데이터-> [훈련 세트 & 테스트세트] \n","  - kneighbors() : k-최근접 이웃 객체의 메서드, 입력한 데이터에 가장 가까운 이웃들 찾아 인덱스 반환\n","  - KNeighborsRegressor() : k-최근접 이웃 회귀 모델\n","  - mean_absolute_error(타깃값, 예측값) : 회귀 모델의 평균 절댓값 오차 계산\n","  - LinearRegression() : 선형 회귀 함수\n","    - coef_, intercept_ : 기울기, y절편\n","  - PolynomialFeatures() : 특성 공학\n","    - degree : 최고 차수 지정\n","    - include_bias=False : 절편을 위한 특성 추가 안함\n","  - transform() : 변환기, 특성을 만들거나 전처리\n","  - StandardScaler() : 표준 점수로 변환\n","  - Ridge() : 규제가 있는 회귀 알고리즘인 릿지 회귀 모델 훈련\n","  - Lasso() : 규제가 있는 회귀 알고리즘인 라쏘 회귀 모델 훈련\n","    - alpha : 규제 강도 조절\n","  - LogisticRegression() : 로지스틱 회귀 함수\n","    - predict_proba() : 예측 확률 반환\n","    - decision_function() : z값 반환, 선형방정식의 출력 반환\n","  - SGDClassifier() : 확률적 경사 하강법을 사용한 분류 모델\n","    - loss : 최적화할 손실 함수 지정\n","    - max_iter : 에포크 횟수 지정\n","\n","- numpy\n","  - seed() : 난수 생성을 위한 정수 초깃값 지정, 초기값이 같으면 동일한 난수 추출 가능\n","  - shuffle(): 주어진 배열을 랜덤하게 섞음\n","  - arrange() : 일정한 간격의 정수/실수 배열 생성\n","  - column_stack(), concatenate() : 전달받은 리스트들을 연결\n","  - reshape() : 배열의 크기 변환\n","\n","- scipy\n","  - expit() : 시그모이드 함수"],"metadata":{"id":"sGq5FDGq1EVk"}}]}